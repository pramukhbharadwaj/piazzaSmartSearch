{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "D0MQwKS-mIn7"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import time\n",
        "import datetime\n",
        "import dateutil.parser\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WP0aMotgmIoA"
      },
      "outputs": [],
      "source": [
        "def isEndorsedByStaff(endorsements):\n",
        "    for endorsement in endorsements:\n",
        "        if 'role' in endorsement and ('professor' in endorsement['role'] or 'instructor' in endorsement['role'] or 'ta' in endorsement['role']):\n",
        "            return True\n",
        "    \n",
        "def checkValidAnswer(post):\n",
        "    return ('i_answer' in post['type']) or ('tag_endorse' in post and isEndorsedByStaff(post['tag_endorse']))\n",
        "\n",
        "def getAnswerList(post):\n",
        "    answerList = []\n",
        "    if('children' in post):\n",
        "        postAnswers = post['children']\n",
        "        for postAnswer in postAnswers:\n",
        "            answer = ''\n",
        "            if 'type' in postAnswer and checkValidAnswer(postAnswer) and 'history' in postAnswer and 'subject' not in postAnswer['history']:\n",
        "                last_modified = getLastModified(postAnswer)\n",
        "                answer = last_modified['content']\n",
        "                answerList.append(answer)\n",
        "    return answerList\n",
        "\n",
        "def getLastModified(post):\n",
        "    history = post['history']\n",
        "    last_modified_answer = history[0]\n",
        "    last_modified_datetime = dateutil.parser.parse(history[0]['created'])\n",
        "    for i in range(0, len(history)):\n",
        "        post_datetime = dateutil.parser.parse(history[i]['created'])\n",
        "        if(post_datetime > last_modified_datetime):\n",
        "            last_modified_datetime = post_datetime\n",
        "            last_modified_answer = history[i]\n",
        "            \n",
        "    return last_modified_answer\n",
        "\n",
        "def extractData(filename):\n",
        "    with open(filename, 'r') as openfile:\n",
        "        input = json.load(openfile)\n",
        "        df = pd.DataFrame(columns = ['Post', 'Sentence'])\n",
        "        for i in range(0, len(input)):\n",
        "            post = input[i]\n",
        "            if 'history' in post:\n",
        "                last_modified = getLastModified(post)\n",
        "                if 'subject' in last_modified and 'content' in last_modified and '<img' not in last_modified['content']:\n",
        "                    subject = last_modified['subject']\n",
        "                    content = last_modified['content']\n",
        "                    post_ID = post['nr']\n",
        "                    answerList = getAnswerList(input[i])\n",
        "                    df = df.append({'Post': post_ID, 'Sentence': subject + \".\" + content}, ignore_index = True)  \n",
        "                    for i in range(0, len(answerList)):\n",
        "                        df = df.append({'Post': post_ID, 'Sentence': answerList[i]}, ignore_index = True)\n",
        "\n",
        "        return df\n",
        "\n",
        "#Removing all contractions\n",
        "def perform_contractions(series):\n",
        "    series = series.apply(lambda x: contractions.fix(x))\n",
        "    return series\n",
        "\n",
        "def data_cleaning(data):\n",
        "\n",
        "  #Convert to Lowercase\n",
        "  data[\"Sentence\"] = data[\"Sentence\"].str.lower()\n",
        "\n",
        "  #Remove all HTML tags\n",
        "  data[\"Sentence\"] = data[\"Sentence\"].apply(lambda x: BeautifulSoup(str(x)).get_text())\n",
        "\n",
        "  #Remove all URLs\n",
        "  data[\"Sentence\"] = data[\"Sentence\"].apply(lambda x: re.sub(r'\\s*(https?://|www\\.)+\\S+(\\s+|$)', \" \", str(x), flags=re.UNICODE))\n",
        "\n",
        "  #Remove extra spaces\n",
        "  data[\"Sentence\"] = data[\"Sentence\"].apply(lambda x: re.sub(r\"\\s+\", \" \", str(x), flags=re.UNICODE).strip())\n",
        "\n",
        "  x = perform_contractions(data[\"Sentence\"])\n",
        "  data[\"Sentence\"] = x\n",
        "\n",
        "  #Removing uppercase letters which might be introduced after removing contractions\n",
        "  data[\"Sentence\"] = data[\"Sentence\"].str.lower()\n",
        "\n",
        "  data = data.drop_duplicates()\n",
        "  data = data.reset_index(drop=True)\n",
        "  return data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rvNBegZCmIoB"
      },
      "outputs": [],
      "source": [
        "#extract\n",
        "data = pd.concat([extractData(\"/content/drive/My Drive/CSCI 544 - Project/piazzaSmartSearch-main/Data/fall_22_nlp.json\"), extractData(\"/content/drive/My Drive/CSCI 544 - Project/piazzaSmartSearch-main/Data/spring_22_nlp.json\")])\n",
        "\n",
        "# Clean\n",
        "data = data_cleaning(data)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}